{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monasteries:  19\n",
      "mosques : 20\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Vignette 2\n",
    "\n",
    "Join all buildings into single graph of multiple components\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# list paths for all monastery .JSONs\n",
    "mon_path = os.path.join(os.path.dirname(os.getcwd()), 'data\\monastaries\\jsons_features')\n",
    "\n",
    "mon_files = []\n",
    "for i in os.listdir(mon_path):\n",
    "    if i.endswith('.json'):\n",
    "        mon_files.append(os.path.join(mon_path, i))\n",
    "\n",
    "# list of paths for all mosque .JSONs\n",
    "mos_path = os.path.join(os.path.dirname(os.getcwd()), 'data\\mosques\\jsons_features')\n",
    "\n",
    "mos_files = []\n",
    "for i in os.listdir(mos_path):\n",
    "    if i.endswith('.json'):\n",
    "        mos_files.append(os.path.join(mos_path, i))                \n",
    "\n",
    "print(\"monasteries: \", len(mon_files))\n",
    "print(\"mosques :\", len(mos_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buildings:  39\n",
      "nodes:  1569\n",
      "edges:  1957\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Combine all jsons into single json\n",
    "\"\"\"\n",
    "\n",
    "# empty dictionary\n",
    "all_buildings = {\n",
    "                 'directed': False,\n",
    "                 'multigraph': False,\n",
    "                 'graph': [],\n",
    "                 'nodes': [],\n",
    "                 'links': []\n",
    "                }\n",
    "\n",
    "# loop through all buildings to create single JSON\n",
    "files = mon_files + mos_files\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    all_buildings['graph'].append(data['graph'])\n",
    "    all_buildings['nodes'].extend(data['nodes'])\n",
    "    all_buildings['links'].extend(data['links'])\n",
    "\n",
    "# save JSON\n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'data\\all\\all_buildings_features.json')\n",
    "\n",
    "with open(path, 'w', encoding ='utf8') as json_file: \n",
    "    json.dump(all_buildings, json_file, indent=4)\n",
    "\n",
    "print('buildings: ', len(all_buildings['graph']))\n",
    "print('nodes: ', len(all_buildings['nodes']))\n",
    "print('edges: ', len(all_buildings['links']))\n",
    "\n",
    "# Why are these quantities different than the first time I did this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save all_buildings as two csv files - buildings file and nodes file\n",
    "\n",
    "Create CSV of just standard features before adding embeddings in later feature\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "\n",
    "# node rows    \n",
    "nodes_header = list(all_buildings['nodes'][0].keys())\n",
    "nodes_rows = []\n",
    "for node in all_buildings['nodes']:\n",
    "    nodes_rows.append(list(node.values()))\n",
    "\n",
    "# Add normalized columns of node area, iso_area and degree\n",
    "i = nodes_header.index('area')\n",
    "j = nodes_header.index('iso_area')\n",
    "k = nodes_header.index('degree')\n",
    "max_area = max([row[i] for row in nodes_rows])\n",
    "max_iso_area = max([row[j] for row in nodes_rows])\n",
    "max_degree = max([row[k] for row in nodes_rows])\n",
    "nodes_header.extend(['area_norm', 'iso_area_norm', 'degree_norm'])\n",
    "for row in nodes_rows:\n",
    "    row.extend([row[i] / max_area, row[j] / max_iso_area, row[k] / max_degree])\n",
    "\n",
    "# Write nodes csv\n",
    "nodes = os.path.join(os.path.dirname(os.getcwd()), 'data\\all\\all_nodes_features.csv')\n",
    "\n",
    "with open(nodes, 'w', newline=\"\", encoding='utf-8') as outFile: \n",
    "    writer = csv.writer(outFile)\n",
    "    writer.writerow(nodes_header)\n",
    "    for row in nodes_rows:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "# building rows\n",
    "bldgs_header = list(all_buildings['graph'][0].keys())\n",
    "bldgs_rows = []\n",
    "for bldg in all_buildings['graph']:\n",
    "    bldgs_rows.append(list(bldg.values()))\n",
    "\n",
    "# Add normalized columns of building num_nodes and num_edges\n",
    "i = bldgs_header.index('num_nodes')\n",
    "j = bldgs_header.index('num_edges')\n",
    "max_nodes = max([row[i] for row in bldgs_rows])\n",
    "max_edges = max([row[j] for row in bldgs_rows])\n",
    "bldgs_header.extend(['num_nodes_norm', 'num_edges_norm'])\n",
    "for row in bldgs_rows:\n",
    "    row.extend([row[i] / max_nodes, row[j] / max_edges])\n",
    "    \n",
    "# write buildings csv\n",
    "bldgs = os.path.join(os.path.dirname(os.getcwd()), 'data\\all\\all_buildings_features.csv')\n",
    "\n",
    "with open(bldgs, 'w', newline=\"\", encoding='utf-8') as outFile: \n",
    "    writer = csv.writer(outFile)\n",
    "    writer.writerow(bldgs_header)\n",
    "    for row in bldgs_rows:\n",
    "        writer.writerow(row)\n",
    "    \n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
